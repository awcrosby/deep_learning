{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Tensorflow Dimensions\n",
    "\n",
    "Using Convolutional Layers in TensorFlow\n",
    "\n",
    "Let's now build a convolutional layer in TensorFlow. In the below exercise, you'll be asked to set up the dimensions of the convolution filters, the weights, and the biases. This is in many ways the trickiest part to using CNNs in TensorFlow. Once you have a sense of how to set up the dimensions of these attributes, applying CNNs will be far more straightforward.\n",
    "\n",
    "You should go over the TensorFlow documentation for [2D convolutions](https://www.tensorflow.org/api_guides/python/nn#Convolution). Most of the documentation is straightforward, except perhaps the padding argument. The padding might differ depending on whether you pass 'VALID' or 'SAME'.\n",
    "\n",
    "Here are a few more things worth reviewing:\n",
    "\n",
    "Introduction to TensorFlow -> TensorFlow Variables.\n",
    "How to determine the dimensions of the output based on the input size and the filter size (shown below). You'll use this to determine what the size of your filter should be.\n",
    "\n",
    "     new_height = (input_height - filter_height + 2 * P)/S + 1\n",
    "     new_width = (input_width - filter_width + 2 * P)/S + 1\n",
    "\n",
    "Instructions\n",
    "\n",
    "Finish off each TODO in the conv2d function.\n",
    "Set up the strides, padding, filter weight (F_w), and filter bias (F_b) such that the output shape is (1, 2, 2, 3). Note that all of these except strides should be TensorFlow variables.\n",
    "    \n",
    "With padding = 'VALID':\n",
    "\n",
    "    out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "    out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "# convolution filter dimensions\n",
    "filter_size_width = 2\n",
    "filter_size_height = 2\n",
    "input_depth = 1\n",
    "output_depth = 3\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal([filter_size_height, filter_size_width, input_depth, output_depth]))\n",
    "    F_b = tf.Variable(tf.zeros(output_depth))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'VALID'  # with padding VALID since is no padding, can get a smaller output since last stride to last window doesnt happen\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Pooling\n",
    "\n",
    "Conceptually, the benefit of the max pooling operation is to reduce the size of the input, and allow the neural network to focus on only the most important elements. Max pooling does this by only retaining the maximum value for each filtered area, and removing the remaining values.\n",
    "\n",
    "TensorFlow provides the tf.nn.max_pool() function to apply max pooling to your convolutional layers.\n",
    "\n",
    "```\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "conv_layer = tf.nn.relu(conv_layer)\n",
    "# apply max pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')\n",
    "```\n",
    "\n",
    "The tf.nn.max_pool() function performs max pooling with the ksize parameter as the size of the filter and the strides parameter as the length of the stride. 2x2 filters with a stride of 2x2 are common in practice.\n",
    "\n",
    "The ksize and strides parameters are structured as 4-element lists, with each element corresponding to a dimension of the input tensor `([batch, height, width, channels])`. For both ksize and strides, the batch and channel dimensions are typically set to 1.\n",
    "\n",
    "with padding = 'VALID':\n",
    "\n",
    "```\n",
    "out_height = ceil(float(in_height - filter_height + 1) / float(strides[1]))\n",
    "out_width  = ceil(float(in_width - filter_width + 1) / float(strides[2]))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full CNN Walkthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# import the MNIST dataset and using a convenient TensorFlow function to\n",
    "# batch, scale, and one-hot encode the data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "# weights: (filter_height, filter_width, input_depth, output_depth)\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The conv2d function computes the convolution against weight W,\n",
    "# and then adds bias b, before applying a ReLU activation function.\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The maxpool2d function applies max pooling to layer x\n",
    "# using a filter of size k.\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer 1 - 28*28*1 to 28*28*32 to 14*14*32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Layer 2 - 14*14*32 to 14*14*64 to 7*7*64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    print('conv2.shape', conv2.shape) #conv2.shape (?, 7, 7, 64)\n",
    "    \n",
    "    # Fully connected layer - 7*7*64 to 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    print('fc1.shape A', fc1.shape) #fc1.shape A (?, 3136)\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    print('fc1.shape B', fc1.shape) #fc1.shape B (?, 1024)\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2.shape (?, 7, 7, 64)\n",
      "fc1.shape A (?, 3136)\n",
      "fc1.shape B (?, 1024)\n",
      "Epoch  1, Batch   1 - Loss: 63504.8125 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch   2 - Loss: 60110.0078 Validation Accuracy: 0.113281\n",
      "Epoch  1, Batch   3 - Loss: 50694.8750 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch   4 - Loss: 45611.5078 Validation Accuracy: 0.136719\n",
      "Epoch  1, Batch   5 - Loss: 35521.7578 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch   6 - Loss: 34439.5703 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch   7 - Loss: 36070.6406 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch   8 - Loss: 32921.6172 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch   9 - Loss: 30002.1367 Validation Accuracy: 0.167969\n",
      "Epoch  1, Batch  10 - Loss: 31986.3535 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  11 - Loss: 26989.9980 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  12 - Loss: 28523.7266 Validation Accuracy: 0.183594\n",
      "Epoch  1, Batch  13 - Loss: 24403.8691 Validation Accuracy: 0.179688\n",
      "Epoch  1, Batch  14 - Loss: 22078.7754 Validation Accuracy: 0.207031\n",
      "Epoch  1, Batch  15 - Loss: 25814.8105 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  16 - Loss: 21400.8125 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  17 - Loss: 24037.5391 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  18 - Loss: 20369.7695 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  19 - Loss: 21392.3223 Validation Accuracy: 0.226562\n",
      "Epoch  1, Batch  20 - Loss: 20458.7500 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  21 - Loss: 20417.0020 Validation Accuracy: 0.222656\n",
      "Epoch  1, Batch  22 - Loss: 17089.9551 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  23 - Loss: 15676.2568 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  24 - Loss: 16724.4102 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  25 - Loss: 19859.2090 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  26 - Loss: 16762.0488 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  27 - Loss: 17019.0938 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  28 - Loss: 15737.9424 Validation Accuracy: 0.250000\n",
      "Epoch  1, Batch  29 - Loss: 14799.4199 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  30 - Loss: 16689.8281 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  31 - Loss: 15040.4033 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  32 - Loss: 15544.0098 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  33 - Loss: 15581.5078 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  34 - Loss: 12282.0371 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  35 - Loss: 13967.0625 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  36 - Loss: 11695.8008 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  37 - Loss: 12925.9414 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  38 - Loss: 13326.2656 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  39 - Loss: 11350.1553 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  40 - Loss: 12775.6582 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  41 - Loss: 13782.5098 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  42 - Loss: 11813.4424 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  43 - Loss: 11213.5713 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  44 - Loss:  9880.4219 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  45 - Loss: 10703.3809 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  46 - Loss: 10390.6924 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  47 - Loss: 10974.3398 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  48 - Loss: 11909.3906 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  49 - Loss:  8848.3115 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  50 - Loss:  7817.1680 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  51 - Loss:  9800.5381 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  52 - Loss:  9876.3604 Validation Accuracy: 0.335938\n",
      "Epoch  1, Batch  53 - Loss: 11119.4707 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  54 - Loss:  9945.0938 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  55 - Loss: 11664.4707 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  56 - Loss:  8232.4268 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  57 - Loss:  9675.6094 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  58 - Loss:  8780.2305 Validation Accuracy: 0.382812\n",
      "Epoch  1, Batch  59 - Loss:  9975.9766 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  60 - Loss:  8122.5210 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  61 - Loss:  8860.5859 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  62 - Loss: 10218.9805 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  63 - Loss: 10682.5059 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  64 - Loss:  8825.2461 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  65 - Loss:  8253.0254 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  66 - Loss:  7296.6084 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  67 - Loss:  8345.5479 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  68 - Loss:  7286.9727 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  69 - Loss:  7202.6538 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  70 - Loss:  8556.5527 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  71 - Loss:  9173.4375 Validation Accuracy: 0.429688\n",
      "Epoch  1, Batch  72 - Loss:  9196.1416 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  73 - Loss:  8450.5117 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  74 - Loss:  9292.4395 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  75 - Loss:  7162.7461 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  76 - Loss:  6302.9590 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  77 - Loss:  7918.0459 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  78 - Loss:  7669.4131 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  79 - Loss:  7784.6045 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  80 - Loss:  6376.3398 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  81 - Loss:  6650.0386 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  82 - Loss:  7945.1855 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  83 - Loss:  6240.3013 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  84 - Loss:  6227.0049 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  85 - Loss:  6956.2256 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  86 - Loss:  6131.0161 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  87 - Loss:  5945.5801 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch  88 - Loss:  7443.2471 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch  89 - Loss:  5451.4653 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  90 - Loss:  5844.3765 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  91 - Loss:  5719.6289 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  92 - Loss:  5846.6523 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch  93 - Loss:  6238.4307 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  94 - Loss:  6096.5576 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  95 - Loss:  5579.0986 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  96 - Loss:  6915.0405 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  97 - Loss:  7488.4507 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  98 - Loss:  7807.0820 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  99 - Loss:  6863.2188 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 100 - Loss:  6031.5337 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 101 - Loss:  5854.9795 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch 102 - Loss:  6256.6030 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 103 - Loss:  5850.9775 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 104 - Loss:  5541.2236 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 105 - Loss:  4989.7432 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 106 - Loss:  4994.5093 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 107 - Loss:  5123.9170 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 108 - Loss:  5553.3271 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 109 - Loss:  4767.3232 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 110 - Loss:  6510.9463 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 111 - Loss:  5007.4785 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 112 - Loss:  5544.8867 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 113 - Loss:  5115.8975 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 114 - Loss:  4882.2427 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 115 - Loss:  6038.4272 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 116 - Loss:  4975.0312 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 117 - Loss:  5160.9609 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 118 - Loss:  5163.1157 Validation Accuracy: 0.562500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 119 - Loss:  4419.4810 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 120 - Loss:  5506.8354 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 121 - Loss:  4449.7676 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 122 - Loss:  4430.1973 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 123 - Loss:  4378.0874 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 124 - Loss:  4760.3232 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 125 - Loss:  3951.0391 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 126 - Loss:  5223.9185 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 127 - Loss:  5262.1777 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 128 - Loss:  5601.1846 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 129 - Loss:  4301.5059 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 130 - Loss:  5778.3564 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 131 - Loss:  3824.4749 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 132 - Loss:  5245.5493 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 133 - Loss:  3920.8933 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 134 - Loss:  5292.1709 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 135 - Loss:  3584.3652 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 136 - Loss:  3668.1763 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 137 - Loss:  4204.0884 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 138 - Loss:  4418.7178 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 139 - Loss:  4843.1484 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 140 - Loss:  3115.1274 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 141 - Loss:  4910.3042 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 142 - Loss:  5217.5391 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 143 - Loss:  4326.6543 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 144 - Loss:  4598.8315 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 145 - Loss:  4491.2856 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 146 - Loss:  4031.3938 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 147 - Loss:  5408.0410 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 148 - Loss:  3732.4243 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 149 - Loss:  4503.0493 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 150 - Loss:  4596.2812 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 151 - Loss:  4692.6621 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 152 - Loss:  4012.2134 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 153 - Loss:  4279.4424 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 154 - Loss:  3629.4836 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 155 - Loss:  5511.8574 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 156 - Loss:  3489.8472 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 157 - Loss:  3228.9968 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 158 - Loss:  3921.3062 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 159 - Loss:  3865.4800 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 160 - Loss:  4019.5408 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 161 - Loss:  4359.2764 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 162 - Loss:  2533.4033 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 163 - Loss:  4621.7988 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 164 - Loss:  3274.7419 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 165 - Loss:  3889.3459 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 166 - Loss:  4500.7246 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 167 - Loss:  3316.3464 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 168 - Loss:  4089.5667 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 169 - Loss:  3245.5171 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 170 - Loss:  2716.5640 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 171 - Loss:  3909.9871 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 172 - Loss:  4003.4263 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 173 - Loss:  4018.4341 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 174 - Loss:  3792.5325 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 175 - Loss:  3334.8145 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 176 - Loss:  3947.4062 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 177 - Loss:  4418.0840 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 178 - Loss:  4366.1855 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 179 - Loss:  3897.3291 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 180 - Loss:  3420.8604 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 181 - Loss:  2900.8494 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 182 - Loss:  4011.5127 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 183 - Loss:  2773.1636 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 184 - Loss:  3711.2764 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 185 - Loss:  2862.6504 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 186 - Loss:  4552.8350 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 187 - Loss:  4159.9033 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 188 - Loss:  3163.6909 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 189 - Loss:  3724.8208 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 190 - Loss:  3064.9329 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 191 - Loss:  3017.5850 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 192 - Loss:  3297.1692 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 193 - Loss:  2817.2019 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 194 - Loss:  3744.1914 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 195 - Loss:  3628.5903 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 196 - Loss:  2496.1672 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 197 - Loss:  3192.2134 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 198 - Loss:  3146.4028 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 199 - Loss:  3574.7864 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 200 - Loss:  3239.8645 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 201 - Loss:  3739.7896 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 202 - Loss:  3106.4290 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 203 - Loss:  2501.7937 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 204 - Loss:  4283.0933 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 205 - Loss:  2864.5264 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 206 - Loss:  2873.9438 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 207 - Loss:  3099.3445 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 208 - Loss:  4048.3767 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 209 - Loss:  3874.8525 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 210 - Loss:  2950.3242 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 211 - Loss:  4359.5332 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 212 - Loss:  3003.2668 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 213 - Loss:  2791.4365 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 214 - Loss:  3242.5127 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 215 - Loss:  3183.7939 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 216 - Loss:  3222.9343 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 217 - Loss:  3697.3101 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 218 - Loss:  2538.2834 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 219 - Loss:  2459.9595 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 220 - Loss:  3032.9509 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 221 - Loss:  1979.6306 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 222 - Loss:  3510.0205 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 223 - Loss:  2485.0811 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 224 - Loss:  3041.8027 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 225 - Loss:  2728.7957 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 226 - Loss:  2531.1755 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 227 - Loss:  2921.9341 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 228 - Loss:  1948.1433 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 229 - Loss:  3173.2310 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 230 - Loss:  2879.5876 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 231 - Loss:  3464.1321 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 232 - Loss:  2735.1489 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 233 - Loss:  2709.1008 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 234 - Loss:  3039.5471 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 235 - Loss:  3129.2622 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 236 - Loss:  3863.8564 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 237 - Loss:  2433.6875 Validation Accuracy: 0.648438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 238 - Loss:  3151.3928 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 239 - Loss:  2398.6333 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 240 - Loss:  2229.5647 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 241 - Loss:  2090.4062 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 242 - Loss:  2915.3984 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 243 - Loss:  1763.4460 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 244 - Loss:  2418.6040 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 245 - Loss:  3065.9321 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 246 - Loss:  3406.3979 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 247 - Loss:  3453.4385 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 248 - Loss:  2763.9233 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 249 - Loss:  2480.1155 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 250 - Loss:  3067.3374 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 251 - Loss:  2334.2568 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 252 - Loss:  2468.4836 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 253 - Loss:  2822.2158 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 254 - Loss:  3099.0051 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 255 - Loss:  2643.5251 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 256 - Loss:  2456.8142 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 257 - Loss:  3500.5837 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 258 - Loss:  1757.8885 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 259 - Loss:  2739.2234 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 260 - Loss:  2837.2605 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 261 - Loss:  2539.6304 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 262 - Loss:  2624.2380 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 263 - Loss:  2172.0935 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 264 - Loss:  2970.8828 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 265 - Loss:  2436.7356 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 266 - Loss:  2972.6553 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 267 - Loss:  2441.4592 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 268 - Loss:  2598.3501 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 269 - Loss:  2852.8384 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 270 - Loss:  3045.8652 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 271 - Loss:  2535.0596 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 272 - Loss:  2646.6279 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 273 - Loss:  2318.2764 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 274 - Loss:  2451.3311 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 275 - Loss:  2096.4980 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 276 - Loss:  3221.6230 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 277 - Loss:  2333.6768 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 278 - Loss:  2685.0569 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 279 - Loss:  1732.5747 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 280 - Loss:  2258.2188 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 281 - Loss:  2884.8066 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 282 - Loss:  2907.8599 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 283 - Loss:  2934.0425 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 284 - Loss:  1909.8770 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 285 - Loss:  2352.4219 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 286 - Loss:  2898.1860 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 287 - Loss:  2492.2310 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 288 - Loss:  2099.6624 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 289 - Loss:  2727.3120 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 290 - Loss:  2272.8657 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 291 - Loss:  2486.4790 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 292 - Loss:  2114.4468 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 293 - Loss:  2140.8301 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 294 - Loss:  2582.5059 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 295 - Loss:  2313.7896 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 296 - Loss:  2365.2793 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 297 - Loss:  1933.3092 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 298 - Loss:  2556.2324 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 299 - Loss:  2469.3281 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 300 - Loss:  2109.6499 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 301 - Loss:  2233.7363 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 302 - Loss:  1735.6270 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 303 - Loss:  2497.4915 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 304 - Loss:  2290.7466 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 305 - Loss:  2256.8269 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 306 - Loss:  1964.3331 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 307 - Loss:  2629.4214 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 308 - Loss:  2291.8936 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 309 - Loss:  1794.8391 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 310 - Loss:  1971.6796 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 311 - Loss:  1314.5840 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 312 - Loss:  2140.4355 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 313 - Loss:  2404.6558 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 314 - Loss:  2378.5903 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 315 - Loss:  1626.1101 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 316 - Loss:  1699.4072 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 317 - Loss:  2083.1846 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 318 - Loss:  2354.6440 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 319 - Loss:  1553.2676 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 320 - Loss:  2384.3970 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 321 - Loss:  1875.4902 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 322 - Loss:  2114.8906 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 323 - Loss:  2133.4453 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 324 - Loss:  2408.3286 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 325 - Loss:  2574.2817 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 326 - Loss:  1844.7432 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 327 - Loss:  2457.4780 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 328 - Loss:  1987.6416 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 329 - Loss:  2894.6638 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 330 - Loss:  2016.6023 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 331 - Loss:  2136.0532 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 332 - Loss:  2466.2222 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 333 - Loss:  2244.6260 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 334 - Loss:  2420.6831 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 335 - Loss:  2140.6001 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 336 - Loss:  1971.1006 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 337 - Loss:  2237.7437 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 338 - Loss:  2623.6702 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 339 - Loss:  2920.1313 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 340 - Loss:  1488.9303 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 341 - Loss:  2242.0293 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 342 - Loss:  2395.2183 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 343 - Loss:  1643.0238 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 344 - Loss:  2281.6577 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 345 - Loss:  1288.4934 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 346 - Loss:  1473.8956 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 347 - Loss:  2001.1252 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 348 - Loss:  2048.0205 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 349 - Loss:  2310.7957 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 350 - Loss:  1471.9463 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 351 - Loss:  1875.9646 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 352 - Loss:  1753.6958 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 353 - Loss:  1685.6094 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 354 - Loss:  2797.1191 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 355 - Loss:  1568.2888 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 356 - Loss:  2010.1509 Validation Accuracy: 0.699219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 357 - Loss:  1431.6216 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 358 - Loss:  2122.5337 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 359 - Loss:  2038.6543 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 360 - Loss:  1941.3779 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 361 - Loss:  1516.3711 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 362 - Loss:  2634.3269 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 363 - Loss:  1482.9420 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 364 - Loss:  2663.9072 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 365 - Loss:  3034.2222 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 366 - Loss:  2637.4536 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 367 - Loss:  1874.5361 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 368 - Loss:  2630.0669 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 369 - Loss:  1727.2632 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 370 - Loss:  1742.6892 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 371 - Loss:  2046.5792 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 372 - Loss:  1603.0192 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 373 - Loss:  2249.0791 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 374 - Loss:  1967.5591 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 375 - Loss:  2301.0164 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 376 - Loss:  1762.4751 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 377 - Loss:  2206.9248 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 378 - Loss:  2281.8350 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 379 - Loss:  1961.3206 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 380 - Loss:  1745.1003 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 381 - Loss:  1876.2966 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 382 - Loss:  1655.8574 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 383 - Loss:  1723.3843 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 384 - Loss:  1639.8350 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 385 - Loss:  2063.7908 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 386 - Loss:  2276.6348 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 387 - Loss:  2010.4490 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 388 - Loss:  1746.8304 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 389 - Loss:  2097.2271 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 390 - Loss:  1939.2751 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 391 - Loss:  2136.6411 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 392 - Loss:  2132.9167 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 393 - Loss:  1217.8262 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 394 - Loss:  1965.5225 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 395 - Loss:  2287.2493 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 396 - Loss:  2105.7803 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 397 - Loss:  2299.9531 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 398 - Loss:  2263.2607 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 399 - Loss:  1466.5829 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 400 - Loss:  2136.3416 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 401 - Loss:  1421.0112 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 402 - Loss:  1815.2659 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 403 - Loss:  2432.8652 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 404 - Loss:  1845.7412 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 405 - Loss:  1747.2937 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 406 - Loss:  1900.3955 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 407 - Loss:  1895.1547 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 408 - Loss:  1733.0587 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 409 - Loss:  1421.7491 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 410 - Loss:  1885.9047 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 411 - Loss:  1406.4949 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 412 - Loss:  2766.7747 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 413 - Loss:  1539.8638 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 414 - Loss:  2273.7354 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 415 - Loss:  1591.2468 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 416 - Loss:  1967.1846 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 417 - Loss:  1873.0754 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 418 - Loss:  1371.7307 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 419 - Loss:  2108.2754 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 420 - Loss:  2252.8477 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 421 - Loss:  1464.7159 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 422 - Loss:  1329.3042 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 423 - Loss:  2038.9402 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 424 - Loss:  2025.7260 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 425 - Loss:  2078.1504 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 426 - Loss:  1762.3008 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 427 - Loss:  1939.8225 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 428 - Loss:  1792.1859 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 429 - Loss:  1804.5391 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   1 - Loss:  1467.7244 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   2 - Loss:  2182.2349 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch   3 - Loss:  1811.4711 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   4 - Loss:  1702.7694 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch   5 - Loss:  1644.7568 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   6 - Loss:  1536.3823 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch   7 - Loss:  2179.0378 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   8 - Loss:  2091.7944 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch   9 - Loss:  1386.8087 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  10 - Loss:  1491.0289 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  11 - Loss:  2113.6494 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  12 - Loss:  1764.6184 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  13 - Loss:  1581.7982 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  14 - Loss:  2318.0566 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  15 - Loss:  1516.7323 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  16 - Loss:  1510.3939 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  17 - Loss:  2271.9607 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  18 - Loss:  1309.5532 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  19 - Loss:  2302.5664 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  20 - Loss:  1901.4534 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  21 - Loss:  1712.2366 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  22 - Loss:  1765.2417 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  23 - Loss:  1410.0232 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  24 - Loss:  1664.8999 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  25 - Loss:  1406.2706 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  26 - Loss:  1761.1431 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  27 - Loss:  1881.9258 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  28 - Loss:  1636.0791 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  29 - Loss:  1750.9553 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  30 - Loss:  1561.6572 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  31 - Loss:  1430.7574 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  32 - Loss:  1937.4996 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  33 - Loss:  2026.1426 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  34 - Loss:  1472.4874 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  35 - Loss:  1358.9098 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  36 - Loss:  2032.4254 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch  37 - Loss:  1617.6495 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  38 - Loss:  1355.7399 Validation Accuracy: 0.710938\n",
      "Epoch  2, Batch  39 - Loss:  1577.0061 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  40 - Loss:  2023.6636 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch  41 - Loss:  1895.4775 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  42 - Loss:  1413.1726 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  43 - Loss:  1763.2954 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  44 - Loss:  1281.3782 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  45 - Loss:  2065.5732 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  46 - Loss:  1675.0164 Validation Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  47 - Loss:  1639.2820 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  48 - Loss:  1497.0621 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  49 - Loss:  1650.5753 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  50 - Loss:  1691.3997 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  51 - Loss:  1519.2786 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch  52 - Loss:  1941.6414 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  53 - Loss:  1287.6765 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  54 - Loss:  1806.5371 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  55 - Loss:  1410.3108 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  56 - Loss:  1561.9172 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  57 - Loss:  1280.5320 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  58 - Loss:  1219.0610 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  59 - Loss:  1541.4604 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  60 - Loss:  1581.6030 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  61 - Loss:  1864.9790 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  62 - Loss:  1271.8232 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  63 - Loss:  1478.5953 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  64 - Loss:  1853.6064 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  65 - Loss:  1561.2104 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  66 - Loss:  1261.9180 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  67 - Loss:  1635.6536 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  68 - Loss:  1301.3547 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  69 - Loss:  1617.5745 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  70 - Loss:  1617.8773 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  71 - Loss:  1009.2499 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  72 - Loss:  1678.5513 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  73 - Loss:  1875.0444 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  74 - Loss:  1909.3635 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  75 - Loss:  2283.5205 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  76 - Loss:  1425.9377 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  77 - Loss:  1385.8451 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  78 - Loss:  1367.1780 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  79 - Loss:  1492.3760 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  80 - Loss:  1578.8271 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  81 - Loss:  1160.7236 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  82 - Loss:  1211.8665 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch  83 - Loss:  1479.5447 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  84 - Loss:  1845.1409 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch  85 - Loss:  1796.4236 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  86 - Loss:  1404.9333 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch  87 - Loss:  1274.5323 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  88 - Loss:  1541.7081 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  89 - Loss:  1692.5354 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  90 - Loss:  2220.3135 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  91 - Loss:  1676.7212 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  92 - Loss:  2181.2581 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  93 - Loss:  1179.4751 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  94 - Loss:  1780.8896 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch  95 - Loss:  2034.5049 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  96 - Loss:  1406.9209 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  97 - Loss:  1436.2458 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  98 - Loss:  1417.2261 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  99 - Loss:  1428.7247 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 100 - Loss:  1343.9735 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 101 - Loss:  1905.9939 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 102 - Loss:  1660.3260 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 103 - Loss:  1180.6914 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 104 - Loss:  1887.7205 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 105 - Loss:  1357.3069 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 106 - Loss:  1093.5795 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 107 - Loss:  1516.2046 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 108 - Loss:  1153.8647 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 109 - Loss:  1439.4956 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 110 - Loss:  1377.6003 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 111 - Loss:  1332.2830 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 112 - Loss:  1410.7791 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 113 - Loss:  1593.6614 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 114 - Loss:  1743.1644 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 115 - Loss:  1564.2301 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 116 - Loss:  1727.3171 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 117 - Loss:  1469.7701 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 118 - Loss:  1822.6331 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 119 - Loss:  1656.1218 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 120 - Loss:  1091.0831 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 121 - Loss:  1294.8368 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 122 - Loss:  2333.2390 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 123 - Loss:  1697.5393 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 124 - Loss:  1300.7102 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 125 - Loss:  1048.0719 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 126 - Loss:  1263.5312 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 127 - Loss:  1076.7988 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 128 - Loss:  1385.0110 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 129 - Loss:  1620.9175 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 130 - Loss:  1117.5042 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 131 - Loss:  1504.0500 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 132 - Loss:   784.0013 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 133 - Loss:  1239.7046 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 134 - Loss:  1203.6082 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 135 - Loss:  1431.3104 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 136 - Loss:  1335.3074 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 137 - Loss:  1320.7094 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 138 - Loss:  1353.7185 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 139 - Loss:  1620.9548 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 140 - Loss:  1289.9666 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 141 - Loss:  1047.0779 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 142 - Loss:   915.3879 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 143 - Loss:  1633.5814 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 144 - Loss:  1551.6174 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 145 - Loss:  1429.9655 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 146 - Loss:   952.3132 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 147 - Loss:  1722.9866 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 148 - Loss:  1387.4023 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 149 - Loss:  2015.8505 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 150 - Loss:  1252.9646 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 151 - Loss:   930.4253 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 152 - Loss:  1455.3179 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 153 - Loss:  1489.0177 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 154 - Loss:  1541.1927 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 155 - Loss:  1478.6720 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 156 - Loss:  1347.6223 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 157 - Loss:  1621.0361 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 158 - Loss:  1365.4152 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 159 - Loss:  1575.3503 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 160 - Loss:  1503.6731 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 161 - Loss:  1228.0200 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 162 - Loss:  1097.9227 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 163 - Loss:  1435.4127 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 164 - Loss:  1395.4639 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 165 - Loss:  1248.5441 Validation Accuracy: 0.726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 166 - Loss:  1373.4391 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 167 - Loss:   943.9290 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 168 - Loss:  1387.8550 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 169 - Loss:  1255.1333 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 170 - Loss:  1149.0410 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 171 - Loss:  1797.3595 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 172 - Loss:  1352.1077 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 173 - Loss:  2171.3667 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 174 - Loss:  1120.4738 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 175 - Loss:  1321.1785 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 176 - Loss:  1391.4006 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 177 - Loss:  1068.0070 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 178 - Loss:  1523.6455 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 179 - Loss:  1342.7070 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 180 - Loss:  1588.0841 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 181 - Loss:  1338.0204 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 182 - Loss:  1458.4800 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 183 - Loss:  1152.7271 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 184 - Loss:  1263.6018 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 185 - Loss:  1328.0881 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 186 - Loss:  1495.6986 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 187 - Loss:  1138.2827 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 188 - Loss:  1546.6245 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 189 - Loss:  1403.1976 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 190 - Loss:  1168.7661 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 191 - Loss:  1256.6956 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 192 - Loss:  1291.2124 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 193 - Loss:  1739.1945 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 194 - Loss:   999.2802 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 195 - Loss:  1148.5203 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 196 - Loss:  1096.2356 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 197 - Loss:  1012.9985 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 198 - Loss:  1532.0736 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 199 - Loss:  1190.5039 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 200 - Loss:  1621.3325 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 201 - Loss:  1640.8542 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 202 - Loss:  1267.6477 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 203 - Loss:  1534.8958 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 204 - Loss:  1411.2617 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 205 - Loss:  1239.4474 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 206 - Loss:  1625.1140 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 207 - Loss:  1386.3032 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 208 - Loss:  1221.4558 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 209 - Loss:  1415.0569 Validation Accuracy: 0.718750\n",
      "Epoch  2, Batch 210 - Loss:  1257.5333 Validation Accuracy: 0.714844\n",
      "Epoch  2, Batch 211 - Loss:  1498.2498 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 212 - Loss:   925.1456 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 213 - Loss:  1307.0477 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 214 - Loss:  1378.8423 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 215 - Loss:  1197.8064 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 216 - Loss:   928.5703 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 217 - Loss:  1025.2878 Validation Accuracy: 0.722656\n",
      "Epoch  2, Batch 218 - Loss:   922.4596 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 219 - Loss:  1287.1475 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 220 - Loss:  2055.5132 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 221 - Loss:  1110.7798 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 222 - Loss:  1435.2480 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 223 - Loss:  1380.1697 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 224 - Loss:  1434.2294 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 225 - Loss:  1284.7428 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 226 - Loss:   744.6212 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 227 - Loss:  1393.4847 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 228 - Loss:   816.4222 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 229 - Loss:  1336.0161 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 230 - Loss:   907.4153 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 231 - Loss:   852.3378 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 232 - Loss:  1293.3248 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 233 - Loss:  1189.2234 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 234 - Loss:  1246.2527 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 235 - Loss:  1203.8315 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 236 - Loss:   901.2310 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 237 - Loss:  1164.7722 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 238 - Loss:  1198.6655 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 239 - Loss:  1119.2131 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 240 - Loss:  1661.5386 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 241 - Loss:  1431.9261 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 242 - Loss:  1246.7015 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 243 - Loss:  1277.4644 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 244 - Loss:   984.0427 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 245 - Loss:  1153.7463 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 246 - Loss:  1267.8726 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 247 - Loss:  1151.1115 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 248 - Loss:  1132.8389 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 249 - Loss:  1065.9624 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 250 - Loss:  1273.2935 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 251 - Loss:  1293.7791 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 252 - Loss:  1071.1790 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 253 - Loss:  1468.8389 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 254 - Loss:  1367.6599 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 255 - Loss:  1162.0874 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 256 - Loss:  1143.6031 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 257 - Loss:  1127.8682 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 258 - Loss:  1099.8406 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 259 - Loss:  1273.2296 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 260 - Loss:   761.8900 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 261 - Loss:  1180.1487 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 262 - Loss:  1159.0334 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 263 - Loss:  1400.2535 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 264 - Loss:  1272.5658 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 265 - Loss:   840.5280 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 266 - Loss:  1120.5746 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 267 - Loss:   839.9762 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 268 - Loss:  1285.7036 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 269 - Loss:  1117.1487 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 270 - Loss:  1023.3961 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 271 - Loss:  1503.1975 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 272 - Loss:  1401.5016 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 273 - Loss:  1525.0410 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 274 - Loss:   825.5113 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 275 - Loss:   927.7557 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 276 - Loss:  1288.0979 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 277 - Loss:  1174.8164 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 278 - Loss:  1435.3348 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 279 - Loss:  1480.6592 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 280 - Loss:  1018.8102 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 281 - Loss:  1312.3632 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 282 - Loss:  1162.3918 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 283 - Loss:  1041.2152 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 284 - Loss:  1138.5482 Validation Accuracy: 0.730469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 285 - Loss:  1082.4272 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 286 - Loss:   967.2251 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 287 - Loss:  1244.7444 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 288 - Loss:  1112.4598 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 289 - Loss:  1019.6605 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 290 - Loss:   792.2307 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 291 - Loss:  1390.8677 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 292 - Loss:  1160.3370 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 293 - Loss:   897.7365 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 294 - Loss:   994.1781 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 295 - Loss:  1016.6824 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 296 - Loss:  1126.1200 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 297 - Loss:  1465.4984 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 298 - Loss:  1190.1331 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 299 - Loss:  1237.7056 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 300 - Loss:  1238.0122 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 301 - Loss:  1238.0022 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 302 - Loss:  1099.0309 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 303 - Loss:  1257.2206 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 304 - Loss:  1264.0812 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 305 - Loss:  1565.3337 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 306 - Loss:  1011.0663 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 307 - Loss:  1131.6493 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 308 - Loss:  1188.4325 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 309 - Loss:   887.8342 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 310 - Loss:   929.2504 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 311 - Loss:  1042.2324 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 312 - Loss:  1288.8372 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 313 - Loss:  1055.8662 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 314 - Loss:  1043.3755 Validation Accuracy: 0.726562\n",
      "Epoch  2, Batch 315 - Loss:  1062.5359 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 316 - Loss:  1007.8749 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 317 - Loss:  1121.6237 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 318 - Loss:  1079.6603 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 319 - Loss:  1100.6084 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 320 - Loss:   776.8928 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 321 - Loss:   798.7632 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 322 - Loss:  1227.0481 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 323 - Loss:  1332.0410 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 324 - Loss:  1349.5859 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 325 - Loss:   816.0403 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 326 - Loss:   910.8992 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 327 - Loss:  1075.3701 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 328 - Loss:   947.4091 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 329 - Loss:  1126.1733 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 330 - Loss:   740.1839 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 331 - Loss:  1276.6554 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 332 - Loss:  1171.9170 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 333 - Loss:  1000.9135 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 334 - Loss:  1236.7197 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 335 - Loss:  1335.5579 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 336 - Loss:  1141.9998 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 337 - Loss:  1081.5831 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 338 - Loss:  1406.7367 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 339 - Loss:  1076.1129 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 340 - Loss:  1326.9731 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 341 - Loss:  1081.1750 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 342 - Loss:  1071.2466 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 343 - Loss:  1136.5583 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 344 - Loss:   862.7220 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 345 - Loss:  1299.6672 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 346 - Loss:  1213.6072 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 347 - Loss:  1043.2715 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 348 - Loss:  1411.6416 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 349 - Loss:  1172.8605 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 350 - Loss:  1054.1323 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 351 - Loss:  1100.9209 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 352 - Loss:   956.1204 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 353 - Loss:  1143.4579 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 354 - Loss:  1429.8568 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 355 - Loss:   790.9898 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 356 - Loss:  1208.5818 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 357 - Loss:  1297.0920 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 358 - Loss:   862.1232 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 359 - Loss:   966.7184 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 360 - Loss:   996.2608 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 361 - Loss:   959.8133 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 362 - Loss:   962.9187 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 363 - Loss:  1043.9624 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 364 - Loss:  1061.0350 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 365 - Loss:  1040.4296 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 366 - Loss:  1104.2633 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 367 - Loss:   766.9099 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 368 - Loss:  1122.6488 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 369 - Loss:  1113.1289 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 370 - Loss:   985.5135 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 371 - Loss:  1292.2190 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 372 - Loss:   870.8668 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 373 - Loss:   843.3683 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 374 - Loss:  1123.4404 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 375 - Loss:   886.7133 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 376 - Loss:   969.8783 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 377 - Loss:  1049.3627 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 378 - Loss:  1045.6400 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 379 - Loss:  1413.6162 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 380 - Loss:  1067.0266 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 381 - Loss:   777.4066 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 382 - Loss:  1186.1686 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 383 - Loss:  1722.8959 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 384 - Loss:  1233.6541 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 385 - Loss:  1178.7766 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 386 - Loss:  1280.0333 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 387 - Loss:  1067.6206 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 388 - Loss:   937.7699 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 389 - Loss:  1300.5288 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 390 - Loss:  1172.0366 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 391 - Loss:  1272.9520 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 392 - Loss:   924.8741 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 393 - Loss:   716.5335 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 394 - Loss:   985.8665 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 395 - Loss:  1126.9387 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 396 - Loss:  1212.1790 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 397 - Loss:  1368.3785 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 398 - Loss:  1212.6187 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 399 - Loss:   825.8889 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 400 - Loss:   919.3041 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 401 - Loss:  1016.6318 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 402 - Loss:  1187.2529 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 403 - Loss:  1203.9753 Validation Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 404 - Loss:   846.8173 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 405 - Loss:  1167.6632 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 406 - Loss:  1196.7371 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 407 - Loss:  1256.8811 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 408 - Loss:  1149.9690 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 409 - Loss:  1123.9224 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 410 - Loss:  1656.4128 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 411 - Loss:  1022.2307 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 412 - Loss:   726.0336 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 413 - Loss:  1215.9146 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 414 - Loss:   631.0196 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 415 - Loss:   796.3546 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 416 - Loss:   962.2841 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 417 - Loss:   836.0347 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 418 - Loss:  1273.1230 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch 419 - Loss:  1027.0845 Validation Accuracy: 0.734375\n",
      "Epoch  2, Batch 420 - Loss:   937.7554 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 421 - Loss:   853.6187 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 422 - Loss:  1128.1421 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 423 - Loss:   624.3268 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 424 - Loss:  1133.3813 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 425 - Loss:   948.0765 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 426 - Loss:  1429.6814 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 427 - Loss:  1316.0548 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 428 - Loss:  1047.3013 Validation Accuracy: 0.730469\n",
      "Epoch  2, Batch 429 - Loss:  1134.6790 Validation Accuracy: 0.726562\n",
      "Epoch  3, Batch   1 - Loss:   927.6174 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch   2 - Loss:   926.8085 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch   3 - Loss:  1025.6562 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch   4 - Loss:  1141.3605 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch   5 - Loss:  1319.9558 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch   6 - Loss:   796.0582 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch   7 - Loss:  1146.9960 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch   8 - Loss:  1188.5801 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch   9 - Loss:  1002.4180 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  10 - Loss:   991.6491 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  11 - Loss:  1165.9032 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  12 - Loss:   937.4534 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  13 - Loss:  1234.5101 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  14 - Loss:   720.6657 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  15 - Loss:  1070.0264 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  16 - Loss:  1204.0231 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  17 - Loss:  1317.8293 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  18 - Loss:  1036.7678 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  19 - Loss:   570.4963 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  20 - Loss:  1128.3721 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  21 - Loss:  1616.6802 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  22 - Loss:   657.5363 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  23 - Loss:   898.8597 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  24 - Loss:   673.8407 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  25 - Loss:  1113.9238 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  26 - Loss:  1215.0781 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  27 - Loss:   937.2871 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  28 - Loss:  1367.5654 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  29 - Loss:   995.7523 Validation Accuracy: 0.726562\n",
      "Epoch  3, Batch  30 - Loss:  1161.0215 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  31 - Loss:   819.4905 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  32 - Loss:  1190.9868 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  33 - Loss:   723.1107 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  34 - Loss:   625.4435 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  35 - Loss:  1159.1221 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  36 - Loss:   970.1782 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  37 - Loss:  1226.8362 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  38 - Loss:  1148.5112 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  39 - Loss:  1296.6809 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  40 - Loss:   850.0061 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  41 - Loss:   970.9945 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  42 - Loss:  1013.3026 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  43 - Loss:   961.7751 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  44 - Loss:   977.7092 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  45 - Loss:   749.8906 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  46 - Loss:  1136.0369 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  47 - Loss:   656.7775 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  48 - Loss:  1143.8375 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  49 - Loss:   877.0294 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  50 - Loss:   747.0966 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  51 - Loss:   594.1311 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  52 - Loss:   600.9542 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  53 - Loss:   966.5745 Validation Accuracy: 0.726562\n",
      "Epoch  3, Batch  54 - Loss:  1109.5635 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  55 - Loss:  1002.7314 Validation Accuracy: 0.726562\n",
      "Epoch  3, Batch  56 - Loss:   900.5950 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  57 - Loss:   837.8036 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  58 - Loss:  1043.7264 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  59 - Loss:   769.4742 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  60 - Loss:   672.9827 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  61 - Loss:   893.4818 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  62 - Loss:  1000.9093 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  63 - Loss:  1126.7142 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  64 - Loss:  1028.9512 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  65 - Loss:   881.4047 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  66 - Loss:   938.2219 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  67 - Loss:   928.6494 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  68 - Loss:   982.5741 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  69 - Loss:  1233.9580 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  70 - Loss:  1128.2380 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  71 - Loss:  1018.0453 Validation Accuracy: 0.730469\n",
      "Epoch  3, Batch  72 - Loss:  1127.1342 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  73 - Loss:   985.8715 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch  74 - Loss:   677.6621 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch  75 - Loss:   998.0679 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  76 - Loss:   717.6503 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  77 - Loss:   937.7987 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  78 - Loss:   976.1007 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  79 - Loss:  1152.7811 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch  80 - Loss:   860.0725 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  81 - Loss:   993.1252 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  82 - Loss:  1106.9768 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  83 - Loss:   885.4067 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch  84 - Loss:  1161.1874 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  85 - Loss:  1069.8639 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  86 - Loss:   851.3206 Validation Accuracy: 0.761719\n",
      "Epoch  3, Batch  87 - Loss:   719.8939 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  88 - Loss:  1018.6497 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  89 - Loss:   906.2142 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  90 - Loss:   892.5803 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  91 - Loss:   713.8621 Validation Accuracy: 0.757812\n",
      "Epoch  3, Batch  92 - Loss:   996.5699 Validation Accuracy: 0.757812\n",
      "Epoch  3, Batch  93 - Loss:   928.3782 Validation Accuracy: 0.750000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3, Batch  94 - Loss:  1081.0493 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  95 - Loss:   802.6968 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  96 - Loss:   882.1772 Validation Accuracy: 0.753906\n",
      "Epoch  3, Batch  97 - Loss:  1073.1251 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  98 - Loss:   607.8214 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch  99 - Loss:  1315.8049 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 100 - Loss:   959.0217 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch 101 - Loss:  1012.7708 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 102 - Loss:   782.6719 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 103 - Loss:   899.2684 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 104 - Loss:   920.7990 Validation Accuracy: 0.750000\n",
      "Epoch  3, Batch 105 - Loss:   906.5851 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 106 - Loss:   859.7889 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 107 - Loss:   844.2109 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch 108 - Loss:   630.8442 Validation Accuracy: 0.746094\n",
      "Epoch  3, Batch 109 - Loss:   844.0374 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch 110 - Loss:   902.6130 Validation Accuracy: 0.738281\n",
      "Epoch  3, Batch 111 - Loss:  1200.5823 Validation Accuracy: 0.734375\n",
      "Epoch  3, Batch 112 - Loss:   898.2696 Validation Accuracy: 0.742188\n",
      "Epoch  3, Batch 113 - Loss:   993.6781 Validation Accuracy: 0.750000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-96700c0749f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_examples\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# Calculate batch loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
